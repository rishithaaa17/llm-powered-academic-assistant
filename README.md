# ğŸ“š Question Paper Generator & Evaluator

A full-stack AI-powered application for generating question papers from study material and evaluating student answers using advanced NLP and LLM technologies.

## ğŸš€ Features

### Backend (FastAPI)
- **Question Paper Generation**: Generate 50-mark question papers with 2, 5, or 10 mark questions
- **Answer Evaluation**: Evaluate individual student answers with detailed feedback
- **Batch Evaluation**: Process multiple answers from CSV files
- **ChromaDB Integration**: Vector storage for efficient text retrieval
- **Graph-based Context**: spaCy-powered concept extraction and relationship mapping
- **DSPy Integration**: Advanced LLM orchestration with Llama3-70B via Groq

### Frontend (Streamlit)
- **ğŸ“˜ Upload Study Material**: File upload and direct text input
- **ğŸ“ Generate Question Paper**: AI-powered question generation with preview
- **âœ… Evaluate Single Answer**: Individual answer evaluation with detailed feedback
- **ğŸ“Š Evaluate from CSV**: Batch evaluation with comprehensive results
- **ğŸ“ˆ Score Summary**: Analytics dashboard with visualizations

## ğŸ—ï¸ Architecture

```
llm-proj/
â”œâ”€â”€ backend/                 # FastAPI Backend
â”‚   â”œâ”€â”€ main.py             # FastAPI app entrypoint
â”‚   â”œâ”€â”€ config.py           # Configuration settings
â”‚   â”œâ”€â”€ utils.py            # Utility functions (ChromaDB, spaCy, etc.)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py      # Pydantic models
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ generate.py     # Question generation endpoints
â”‚   â”‚   â””â”€â”€ evaluate.py     # Evaluation endpoints
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ llm_service.py  # DSPy LLM service
â”œâ”€â”€ frontend/               # Streamlit Frontend
â”‚   â”œâ”€â”€ main.py            # Main Streamlit app
â”‚   â”œâ”€â”€ pages.py           # Page functions
â”‚   â””â”€â”€ requirements.txt   # Frontend dependencies
â”œâ”€â”€ requirements.txt       # Backend dependencies
â””â”€â”€ README.md             # This file
```

## ğŸ› ï¸ Setup Instructions

### Prerequisites
- Python 3.8+
- Groq API key (for Llama3-70B access)
- spaCy English model

### 1. Clone and Setup
```bash
git clone <repository-url>
cd llm-proj
```

### 2. Install Dependencies

#### Backend Setup
```bash
# Install backend dependencies
pip install -r requirements.txt

# Install spaCy English model
python -m spacy download en_core_web_sm
```

#### Frontend Setup
```bash
# Install frontend dependencies
cd frontend
pip install -r requirements.txt
```

### 3. Environment Configuration
```bash
# Copy example environment file
cp env.example .env

# Edit .env file with your Groq API key
GROQ_API_KEY=your_groq_api_key_here
```

### 4. Start the Application

#### Start Backend
```bash
# From project root
cd backend
python start.py
```
Backend will be available at: http://localhost:8000
API Documentation: http://localhost:8000/docs

#### Start Frontend
```bash
# From project root
cd frontend
python start.py
```
Frontend will be available at: http://localhost:8501

## ğŸ“– Usage Guide

### 1. Upload Study Material
- Navigate to "ğŸ“˜ Upload Study Material"
- Upload a `.txt` file or paste text directly
- Study material is processed and stored in ChromaDB

### 2. Generate Question Paper
- Go to "ğŸ“ Generate Question Paper"
- Click "Generate Question Paper" button
- Download generated paper as text or CSV

### 3. Evaluate Answers
- **Single Answer**: Use "âœ… Evaluate Single Answer" page
- **Batch Evaluation**: Use "ğŸ“Š Evaluate from CSV" page
- Upload CSV files with questions and student answers

### 4. View Analytics
- Visit "ğŸ“ˆ Score Summary" for detailed analytics
- Upload evaluation results CSV for visualization

## ğŸ”§ API Endpoints

### Generation
- `POST /api/v1/generate/paper` - Generate from file upload
- `POST /api/v1/generate/paper/text` - Generate from text input

### Evaluation
- `POST /api/v1/evaluate/one` - Evaluate single answer (file upload)
- `POST /api/v1/evaluate/one/text` - Evaluate single answer (text input)
- `POST /api/v1/evaluate/csv` - Batch evaluation from CSV files
- `POST /api/v1/evaluate/csv/text` - Batch evaluation from base64 CSV

## ğŸ“Š CSV Formats

### Questions CSV
```csv
question_text,marks,answer_text
"What is machine learning?",5,"Machine learning is..."
"Explain neural networks.",10,"Neural networks are..."
```

### Student Answers CSV
```csv
question_number,student_answer
1,"Machine learning is a subset of AI..."
2,"Neural networks are computational models..."
```

## ğŸ§  Technical Stack

### Backend
- **FastAPI**: Modern, fast web framework
- **DSPy**: Advanced LLM orchestration
- **ChromaDB**: Vector database for embeddings
- **spaCy**: NLP for concept extraction
- **SentenceTransformers**: Text embeddings
- **NetworkX**: Graph operations
- **Pydantic**: Data validation

### Frontend
- **Streamlit**: Rapid web app development
- **Plotly**: Interactive visualizations
- **Pandas**: Data manipulation
- **Requests**: HTTP client

### AI/ML
- **Llama3-70B**: Large language model (via Groq)
- **all-MiniLM-L6-v2**: Sentence embeddings
- **en_core_web_sm**: spaCy English model

## ğŸ” Security Features

- CORS configuration for frontend-backend communication
- Input validation with Pydantic models
- Error handling and logging
- Environment variable configuration

## ğŸš€ Deployment

### Local Development
```bash
# Terminal 1: Backend
cd backend && python start.py

# Terminal 2: Frontend  
cd frontend && python start.py
```

### Production
- Use production WSGI server (Gunicorn) for FastAPI
- Configure environment variables
- Set up proper CORS origins
- Use HTTPS in production

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ†˜ Troubleshooting

### Common Issues

1. **spaCy model not found**
   ```bash
   python -m spacy download en_core_web_sm
   ```

2. **ChromaDB connection issues**
   - Check if ChromaDB is running
   - Verify collection permissions

3. **Groq API errors**
   - Verify API key in environment variables
   - Check API quota and limits

4. **Frontend can't connect to backend**
   - Ensure backend is running on port 8000
   - Check CORS configuration
   - Verify network connectivity

### Debug Mode
```bash
# Backend debug mode
DEBUG=True python backend/start.py

# Frontend debug mode
streamlit run frontend/main.py --logger.level debug
```

## ğŸ“ Support

For issues and questions:
1. Check the troubleshooting section
2. Review API documentation at http://localhost:8000/docs
3. Open an issue on GitHub

---

**Built with â¤ï¸ using FastAPI, Streamlit, and DSPy** 